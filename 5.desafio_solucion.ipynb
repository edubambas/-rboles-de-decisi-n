{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "armed-berry",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-battery",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este desafío vamos a compara la performance de modelos de árboles de clasificación con el objetivo de mostrar que modelos más complejos no siempre performan mejor que los más simples. \n",
    "\n",
    "Vamos a entrenar varios modelos de clasificación basados en árboles de decisión para predecir si una pelicula va a obtener un premio oscar o no. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-commission",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "En esta clase usaremos un dataset con info de películas (\"Movie_classification.csv\").  \n",
    "Este dataset esta conformado por los siguientes features:  \n",
    "\n",
    " *   **Marketing expense:**    (float64)    Gasto total en Marketing      \n",
    " *   **Production expense:**   (float64)    Gasto total de Producción\n",
    " *   **Multiplex coverage:**   (float64)    Cobertura promedio de Multiplex\n",
    " *   **Budget:**               (float64)    Presupuesto\n",
    " *   **Movie_length:**         (float64)    Duración de la película\n",
    " *   **Lead_ Actor_Rating:**   (float64)    Puntaje sobre el actor principal\n",
    " *   **Lead_Actress_rating:**  (float64)    Puntaje sobre la actriz principal\n",
    " *   **Director_rating:**      (float64)    Puntaje sobre el Director\n",
    " *   **Producer_rating:**      (float64)    Puntaje sobre el Productor\n",
    " *   **Critic_rating:**        (float64)    Puntaje que le puso la crítica\n",
    " *   **Trailer_views:**        (int64)      Cantidad de vistas del Trailer\n",
    " *   **3D_available:**         (object)     Si esta disponible en 3D (Yes/No)\n",
    " *   **Time_taken:**           (float64)    Duración de la película\n",
    " *   **Twitter_hastags:**      (float64)    Cantidad de menciones en twitter\n",
    " *   **Genre:**                (object)     Genero de la película\n",
    " *   **Avg_age_actors:**       (int64)      Edad promedio de los actores\n",
    " *   **Num_multiplex:**        (int64)      Cantidad de Multiplex\n",
    " *   **Collection:**           (int64)      Recaudación\n",
    " *   **Start_Tech_Oscar:**     (int64)      Si recibió un oscar o no.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-amount",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-leather",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Con la preparación de datos que hicimos en la notebook de checkpoint, creemos dos archivos csv uno para los datos de train y otro para los datos de test.\n",
    "\n",
    "Guardemos los archivos en la carpeta Data de esta clase, con los campos separados por tab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-discovery",
   "metadata": {},
   "source": [
    "Después del ejercicio 5 de la práctica de checkpoint, guardamos los archivos de este modo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-wilderness",
   "metadata": {},
   "source": [
    "```\n",
    "X_train.to_csv(\"../Data/Movie_classification_train_X.csv\", sep=\"\\t\", header=True, index = False)\n",
    "\n",
    "X_test.to_csv(\"../Data/Movie_classification_test_X.csv\", sep=\"\\t\", header=True, index = False)\n",
    "\n",
    "y_train.to_csv(\"../Data/Movie_classification_train_y.csv\", sep=\"\\t\", header=True, index = False)\n",
    "\n",
    "y_test .to_csv(\"../Data/Movie_classification_test_y.csv\", sep=\"\\t\", header=True, index = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-complex",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Leamos desde la carpeta Data, en instancias de DataFrame, los datos de train y test resultados del paso anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../Data/Movie_classification_train_X.csv\", sep=\"\\t\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"../Data/Movie_classification_train_y.csv\", sep=\"\\t\")\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"../Data/Movie_classification_test_X.csv\", sep=\"\\t\")\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(\"../Data/Movie_classification_test_y.csv\", sep=\"\\t\")\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-netherlands",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Usando los parametros por default de `DecisionTreeClassifier`entrenemos un modelo de clasificación que prediga si una película es ganadora de Un premio Oscar\n",
    "\n",
    "Grafiquemos el árbol obtenido y observemos la complejidad del modelo creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_default_tree_gini = tree.DecisionTreeClassifier(random_state=17)\n",
    "my_default_tree_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_default_tree_gini.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = my_default_tree_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "tree.plot_tree(my_default_tree_gini,feature_names = X_train.columns,filled=True,rounded=True, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-andrews",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Sabemos que el modelo por default usa Gini como criterio de pureza.\n",
    "\n",
    "Comparemos el modelo obtenido en el punto anterior con uno que use entropía. \n",
    "\n",
    "Para eso, entrenemos el modelo con todos los parámetros por default, excepto el criterio de pureza, y evaluemos las métricas de accuracy y confusion matrix para ambos modelos.\n",
    "\n",
    "Grafiquemos el modelo obtenido.\n",
    "\n",
    "¿Podemos concluir que la performance de ambos modelos es equivalente?\n",
    "\n",
    "Estos modelos ¿emplean en la clasificación todas las variables disponibles en el dataset? ¿Difieren las variables seleccionadas en cada uno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_default_tree_entropy = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state=17)\n",
    "my_default_tree_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_default_tree_entropy.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = my_default_tree_entropy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "tree.plot_tree(my_default_tree_entropy,feature_names = X_train.columns,filled=True,rounded=True, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-cover",
   "metadata": {},
   "source": [
    "**¿Podemos concluir que la performance de ambos modelos es equivalente?**\n",
    "\n",
    "Sí, los valores de accuracy y confusion matrix obtenidos son muy similares.\n",
    "\n",
    "**Estos modelos ¿emplean en la clasificación todas las variables disponibles en el dataset? ¿Difieren las veariables seleccionadas en cada uno?**\n",
    "\n",
    "Mirando los valores de `feature_importances_`vemos que en cada modelo hay dos variables que no se usan como predictoras, pero son distintas en cada uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_gini_unused = my_default_tree_gini.feature_importances_ == 0\n",
    "X_train.columns[mask_gini_unused]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_entropy_unused = my_default_tree_entropy.feature_importances_ == 0\n",
    "X_train.columns[mask_entropy_unused]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-arizona",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "Elijamos las cuatro variables de mayor importancia como variables predictoras y entrenemos otros dos modelos usando gini y entropia, definiendo como profundidad máxima 7.\n",
    "\n",
    "Comparemos la performance obtenida con los entrenados en los ejercicios anteriores.\n",
    "\n",
    "Grafiquemos estos dos nuevos modelos.\n",
    "\n",
    "¿Qué podemos concluir comparando los cuatro modelos entrenados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_importance = pd.DataFrame({'atributo':X_train.columns, \n",
    "                                'importancia': my_default_tree_gini.feature_importances_}).sort_values('importancia', ascending = False).iloc[0:4, :]\n",
    "gini_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_features = gini_importance.atributo.values\n",
    "gini_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_default_tree_entropy.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_importance = pd.DataFrame({'atributo':X_train.columns, \n",
    "                                'importancia': my_default_tree_entropy.feature_importances_}).sort_values('importancia', ascending = False).iloc[0:4, :]\n",
    "entropy_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_features = entropy_importance.atributo.values\n",
    "entropy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree_gini_4 = tree.DecisionTreeClassifier(random_state=17, max_depth = 7)\n",
    "my_tree_gini_4.fit(X_train.loc[:, gini_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree_entropy_4 = tree.DecisionTreeClassifier(random_state=17, max_depth = 7, criterion = \"entropy\")\n",
    "my_tree_entropy_4.fit(X_train.loc[:, entropy_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_gini_4 = my_tree_gini_4.predict(X_test.loc[:, gini_features])\n",
    "y_pred_test_entropy_4 = my_tree_entropy_4.predict(X_test.loc[:, entropy_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred_test_gini_4, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred_test_entropy_4, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred_test_gini_4, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred_test_entropy_4, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "tree.plot_tree(my_tree_gini_4,feature_names = X_train.columns,filled=True,rounded=True, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "tree.plot_tree(my_tree_entropy_4,feature_names = X_train.columns,filled=True,rounded=True, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-bailey",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Vemos que \n",
    "\n",
    "* Los distintos criterios de pureza generan modelos distintos.\n",
    "\n",
    "* La performance obtenida cuando sólo variamos el criterio de pureza y todos los demás parametros son iguales, es bastante parecida.\n",
    "\n",
    "* Simplificando en extremo los árboles (sólo 4 features y limitando la altura máxima) obtenemos modelos de performance similar a los más complejos. Incluso si comparamos con el mejor árbol obtenido con cross validation en la práctica de checkpoint.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "65ec09165af5bea57fc582485f497cad0155a37ff508e428f9e21fe9cac1c034"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
